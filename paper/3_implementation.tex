%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Загрузка данных и выполнение запросов}

\subsection{Развёртывание кластера Dgraph}

Для развёртывания кластера Dgraph используется инструмент Docker Compose~\cite{dockerCompose}, предназначенный для
работы с мультиконтейнерными приложениями. Это позволяет развёртывать узлы кластера Dgraph в изолированных процессах ---
Docker-контейнерах, что не требует выполнения предварительных работ на основном устройстве, а также позволяет
единственный раз настроить работу контейнеров и их взаимодействие в конфигурационном файле Docker Compose. В листинге
\ref{lst:compose} приложения A приводится конфигурационный файл \texttt{compose.yml} кластера Dgraph.

Кластер Dgraph составляют один Zero-узел и один Alpha-узел, разделяющие единое хранилище данных (Docker volume).
Zero-узел использует следующие порты:
\begin{itemize}
  \item 5080 для внутрикластерного взаимодействия и работы с инструментами импорта данных Dgraph (Live Loader, Bulk
    Loader) по протоколу gRPC;
  \item 6080 для администрирования кластером по протоколу HTTP.
\end{itemize}

Alpha-узел использует следующие порты:
\begin{itemize}
  \item 7080 для взаимодействия внутри кластера по протоколу gRPC;
  \item 8080 для обработки клиентских запросов по протоколу HTTP;
  \item 9080 для обработки клиентских запросов по протоколу gRPC.
\end{itemize}

\subsection{Преобразование исходных данных}

Импорт данных в новый кластер будет осуществляться с использованием инструмента Dgraph Bulk Loader. Bulk loader
принимает данные в формате JSON или Dgraph-расширении формата RDF, однако исходные данные представлены в формате CSV.
Таким образом, возникают задачи:
\begin{enumerate}
  \item непосредственной конвертации форматов данных;
  \item логического преобразование данных из реляционной модели в графовую модель.
\end{enumerate}

В документации Dgraph для конвертации форматов CSV в JSON рекомендуется использовать инструмент
csv2json~\cite{csv2json}, что решает первую задачу. Для решения второй задачи предлагается передавать на вход утилите
jq~\cite{jq} результат конвертации, а также текст программы на высокоуровневом функциональном языке программирования JQ,
предназначенном для преобразования литералов JSON. Это решает задачу подготовки данных, но требует написания
индивидуальных, во многом дублирующих друг друга, программ на языке JQ для каждого набора данных. Более универсальным
решением будет реализация собственного инструмента, способного по некоторому описанию исходных файлов и правил их
преобразования генерировать данные в нужном виде. Поставим задачу разработки такого инструмента.

\subsection{Проектирование преобразователя данных}

\subsubsection{Формат входных и выходных данных}

Для описания правил преобразования исходных файлов достаточно возможностей формата YAML --- требуемое представляется на
нём просто и естественно, синтаксис описания нетрудно корректируется, а средства анализа YAML распространены.
Обрабатываемые файлы описываются в одном YAML-файле, который далее мы будем называть \textit{конфигурационным}.

Чтобы упростить работу с определением расположения файлов, целесообразно хранить их в структурированном виде. Определим,
что исходные файлы будут располагаться в одной директории с именем \texttt{source}, а соответствующий конфигурационный
файл \texttt{convert.yml} --- находиться непосредственно рядом с \texttt{source}. Директорию, содержащую \texttt{source}
и \texttt{convert.yml}, будем называть \textit{корневой директорией}.

Целевым форматом преобразования будет Dgraph-расширение формата RDF: оно выразительнее JSON, поскольку позволяет при
необходимости явно назначать объектам типы данных. Результат преобразования будет сохраняться в файле
\texttt{output.rdf} в корневой директории набора.

Таким образом, преобразователю достаточно будет передать путь к корневой директории, где впоследствии будет сгенерирован
пригодный для импорта файл \texttt{output.rdf}. Удобной будет опция передачи преобразователю пути к директории с
несколькими корневым директориям сразу для параллельной (при возможности) обработки соответствующих наборов данных.

\subsubsection{Спецификация конфигурационного файла}

На верхнем уровне конфигурационного файла \texttt{convert.yml} должен быть определён массив \texttt{files}, содержащий
описания обрабатываемых файлов. Незадействованные файлы описывать в \texttt{files} не нужно. Файлы обрабатываются в
порядке их следования в массиве \texttt{files}. Ниже определяются допустимые поля в описании файлов. Все поля по
умолчанию считаются обязательными, если явно не оговорено обратное.

\paragraph{Поле \texttt{name}}

Определяет имя обрабатываемого файла.

\paragraph{Поле \texttt{delimiter}}

Определяет символ, разделяющий столбцы в файле. Поле опциональное, и по умолчанию разделителем является запятая, что
соответствует формату CSV. При работе с форматом TSV разделителем является символ табуляции \texttt{\textbackslash t}.
Символы возврата каретки \texttt{\textbackslash r} или перевода строки \texttt{\textbackslash n} не могут быть
разделителями.

\paragraph{Поле \texttt{comment}}

Определяет символ, являющийся началом однострочного комментария. Поле опциональное. Все строки файла, начинающиеся
непосредственно с \texttt{comment}, игнорируются. Если \texttt{comment} стоит не в начале строки, он считается обычным
символом. Символ начала комментария не может совпадать с \texttt{delimiter} или быть равным \texttt{\textbackslash r},
\texttt{\textbackslash n}.

\paragraph{Поле \texttt{declarations}}

Массив с объявлениями имён и типов столбцов файла, используемых в правилах преобразования. Каждое объявление содержит
\begin{itemize}
  \item поле \texttt{name} --- имя столбца;
  \item поле \texttt{type} --- тип (данных) стобца. Поддерживаемые типы: строка \texttt{string}, целое число
    \texttt{int} (32 бита), число с плавающей запятой \texttt{float} (64 бита) и идентификатор \texttt{id}. Типы данных
    \texttt{string}, \texttt{int} и \texttt{float} также будут называться \textit{тривиальными};
  \item поле \texttt{prefix} (устанавливается, только если \texttt{type} --- \texttt{id}). Если атрибут определён, все
    значения столбца будут предварены указанным префиксом --- это необходимо для обеспечения уникальности
    blank-идентификаторов. Действительно, поскольку идентификаторы в реляционных таблицах обычно целочисленные,
    blank-идентификаторы c одинаковым номером, но соответствующие разным сущностям, совпадут. Присоединение различных
    префиксов обеспечит blank-идентификаторам уникальность. Как следствие, если одна и та же сущность используется в
    различных исходных файлах, префикс её идентификаторов должен совпадать везде (или везде отсутствовать).
\end{itemize}

Подчеркнём, что все столбцы, используемые в правилах преобразования, должны быть определены в массиве
\texttt{declarations}. Незадействованные столбцы файла определять в \texttt{declarations} не следует.

\paragraph{Поле \texttt{artificial\_declaration}}

Объявление искусственного столбца, данные которого генерируются во время работы преобразователя. В данный момент
используется только для генерации искусственных идентификаторов, когда они явно не указываются в исходных файлах
(например, в наборе данных \ref{datasetERC20} не предусмотрены идентификаторы переводов в
\texttt{token\_transfers.csv}). Искусственное объявление содержит те же поля, что и обычное объявление: \texttt{name},
\texttt{type} (только \texttt{id}) и \texttt{prefix}.

\paragraph{Поле \texttt{entity\_facets}}

Введём необходимый контекст. Сущность реляционной модели, хранящая информацию о сопоставлении других сущностей, в
графовой модели переходит в отношение между этими сущностями. Исходную сущность назовём \textit{соединительной}.
Атрибуты соединительной сущности переходят в атрибуты соответствующего отношения, или фасеты, которые в Dgraph
назначаются ребру все и в рамках одного объявления. Поскольку атрибуты соединительной сущности могут располагаться в
разных реляционных таблицах, обрабатывая файлы приходится <<накапливать>> фасеты, ассоциированные с этой сущностью, до
тех пор, пока они не будут собраны все. Только после этого полученные фасеты можны добавить к фасетам выписываемого
литерала RDF.

Итак, поле \texttt{entity\_facets} определяет массив правил, по которым в памяти преобразователя сохраняются фасеты,
ассоциированные с соединительной сущностью. Каждое такое правило содержит
\begin{itemize}
  \item поле \texttt{id} --- имя столбца идентификаторов соединительной сущности;
  \item поле \texttt{key} --- имя ключа фасета, которое будет использоваться в Dgraph;
  \item поле \texttt{value} --- имя столбца значений фасета. Столбец должен быть тривиального типа.
\end{itemize}

Таким образом, для каждого правила массива \texttt{enitity\_facets} со всяким идентификатором из столбца \texttt{id}
будет ассоциирован фасет с ключом \texttt{key} и соответствующим значением столбца \texttt{value}. Сохранение фасетов
происходит перед выписыванием литералов RDF.

\paragraph{Поле \texttt{rdfs}}

Массив правил, по которым в \texttt{output.rdf} выписываются литералы RDF. Каждое такое правило содержит
\begin{itemize}
  \item поле \texttt{subject} --- имя столбца субъекта RDF. Столбец должен быть типа \texttt{id};
  \item поле \texttt{predicat} --- имя соответствующего предиката схемы Dgraph;
  \item поле \texttt{object} --- имя столбца объекта RDF;
  \item опциональное поле \texttt{cast\_object\_to} --- изменённый тип объекта. Используется, если необходимо
    выполнить преобразование типа объекта RDF (например, чтобы интерпретировать столбец типа \texttt{id} как
    \texttt{int} для получения буквального значения идентификатора);
  \item опциональное поле \texttt{entity\_facets\_id} --- имя столбца идентификаторов соединительной сущности.
    Применяется, если к фасетам данного литерала RDF необходимо добавить фасеты, ассоциированные с соединительной
    сущностью;
  \item опциональное поле \texttt{facets} --- массив описаний фасетов, добавляемых к фасетам данного литерала RDF.
    Отличается от \texttt{entity\_facets\_id} тем, что фасеты \texttt{facets} не ассоциированы с какой-либо сущностью, а
    их значения берутся непосредственно из обрабатываемого файла. Каждое описание фасета содержит
    \begin{itemize}
      \item поле \texttt{key} --- имя ключа фасета, которое будет использоваться в Dgraph;
      \item поле \texttt{value} --- имя столбца значений фасета. Столбец должен быть тривиального типа.
    \end{itemize}
\end{itemize}

\subsubsection{Конфигурационные файлы тестовых наборов данных}

Приведём конфигурационные файлы \texttt{convert.yml} тестовых наборов данных. В листинге \ref{lst:elliptic:config}
приложения А приводится фрагмент конфигурационного файла набора Elliptic++ Transactions, в листинге
\ref{lst:mooc:config} приложения А --- фрагмент конфигурационного файла набора MOOC User Actions, в листинге
\ref{lst:roadnet:config} приложения А --- конфигурационный файл набора California Road Network и в листинге
\ref{lst:erc20:config} приложения А --- фрагмент конфигурационного файла набора Stablecoin ERC20 Transactions.

\subsubsection{Модули преобразователя}

При проектировании преобразователя естественным образом выделяются два модуля:
\begin{enumerate}
  \item Модуль работы с RDF. Содержит структуры данных для представления в программе литералов Dgraph-расширения
    формата RDF, а также необходимые методы работы с ними.
  \item Модуль преобразования. Содержит структуры данных для представления конфигурационного файла, методы валидации
    структур и всю основную функциональность преобразования.
\end{enumerate}

Для описания функциональности модулей частично используется объектно-ориентированная терминология: понятия объекта,
метода, конструктора и др. Говоря, что модуль <<предоставляет>> некоторое определение, подразумевается, что оно
публичное, т.е. может использоваться другими модулями.

\subsubsection{Модуль работы с RDF}

Определим представление субъекта, предиката и объекта RDF --- термов RDF --- в программе. Заметим, что в терме можно
выделить его значение, а также <<оформление>> этого значения, влияющее на контекст использования. Например,
blank-идентификатор указывается без оформления, UID обрамляется треугольными скобками, а литеральное значение берётся в
двойные кавычки.

Введём тип перечисления (enumeration) \texttt{Decoration} с допустимыми значениями \texttt{None}, \texttt{AngleBrackets}
и \texttt{Quotes}. Тогда терм RDF будет представляться структурой \texttt{Term} с полями
\begin{itemize}
  \item \texttt{value} --- значение терма;
  \item \texttt{decoration} --- оформление значения терма типа \texttt{Decoration}.
\end{itemize}

Значения фасетов RDF также могут иметь оформление. Например, целочисленный литерал ничем не обрамляется, а строковый ---
берётся в двойные кавычки. Соответственно, фасет RDF представляется структурой \texttt{Facet} с полями
\begin{itemize}
  \item \texttt{key} --- имя ключа фасета;
  \item \texttt{value} --- значение фасета;
  \item \texttt{decoration} --- оформление значения фасета типа \texttt{Decoration}.
\end{itemize}

Структура \texttt{Rdf} представляет литерал RDF (с фасетами). \texttt{Rdf} содержит поля
\begin{itemize}
  \item \texttt{subject} --- субъект RDF типа \texttt{Term};
  \item \texttt{predicat} --- предикат RDF типа \texttt{Term};
  \item \texttt{object} --- объект RDF типа \texttt{Term};
  \item \texttt{facets} --- массив фасетов RDF типа \texttt{Facet}.
\end{itemize}

Модуль предоставляет тип \texttt{Decoration}, структуры \texttt{Term}, \texttt{Facet} и \texttt{Rdf} и их поля, а также
функции создания этих структур и методы их сериализации.

\subsubsection{Модуль преобразования}

Предполагается, что для представления конфигурационного файла сущностями в программе используется некоторый инструмент
десериализации YAML. Поскольку исходный конфигурационный файл может содержать ошибки, указанные сущности необходимо
валидировать: проверять отсутствие необъявленных значений в правилах, соответствие типов используемых столбцов
контекстным ограничениям и т.п. Далее при определении структур данных будем подразумевать, что для них определены методы
валидации соответственно спецификации конфигурационного файла.

\paragraph{Представление правил}

Правило сохранения фасета, ассоциированного с соединительной сущностью, представляется структурой
\texttt{EntityFacetRule}. Структура содержит поля
\begin{itemize}
  \item \texttt{id} --- имя столбца идентификаторов соединительной сущности;
  \item \texttt{key} --- имя ключа фасета;
  \item \texttt{value} --- имя столбца значений фасета.
\end{itemize}

Правило выписывания литерала RDF может содержать описания фасетов, добавляемых к фасетам данного литерала RDF, не
ассоциированных с какой-либо соединительной сущностью, и значения которых берутся непосредственно из текущего файла.
Они представляются структурой \texttt{FacetRule} с полями
\begin{itemize}
  \item \texttt{key} --- имя ключа фасета;
  \item \texttt{value} --- имя столбца значений фасета.
\end{itemize}

Правило выписывания литерала RDF представляется структурой \texttt{RdfRule}. Стуктура содержит поля
\begin{itemize}
  \item \texttt{subject} --- имя столбца субъекта RDF;
  \item \texttt{predicat} --- имя предиката RDF;
  \item \texttt{object} --- имя столбца объекта RDF;
  \item \texttt{cast\_object\_to} --- изменённый тип объекта RDF;
  \item \texttt{facets} --- массив правил \texttt{FacetRule};
  \item \texttt{entityFacetsId} --- имя столбца идентификаторов соединительной сущности.
\end{itemize}

\paragraph{Обработка файлов}

Для представления допустимых типов столбцов файла вводится перечисление \texttt{DataType}, содержащее элементы
\texttt{String}, \texttt{Int}, \texttt{Float} и \texttt{Id}.

Объявление имени и типа столбца файла, используемое в правилах преобразования \texttt{FacetRule},
\texttt{EntityFacetRule} и \texttt{RdfRule}, представляется структурой \texttt{Declaration}. Структура содержит поля
\begin{itemize}
  \item \texttt{name} --- имя столбца в файле;
  \item \texttt{type} --- тип столбца из \texttt{DataType};
  \item \texttt{prefix} --- префикс идентификатора.
\end{itemize}

Описание исходного файла и правила его преобразования представляется структурой \texttt{File}. Структура содержит поля
\begin{itemize}
  \item \texttt{name} --- имя файла;
  \item \texttt{delimiter} --- символ разделителя столбцов в файле;
  \item \texttt{comment} --- символ начала однострочного комментария;
  \item \texttt{declarations} --- массив объявлений типа \texttt{Declaration};
  \item \texttt{artificial\_declaraion} --- искусственное объявление типа \texttt{Declaration};
  \item \texttt{entityFacets} --- массив правил типа \texttt{EntityFacet};
  \item \texttt{rdfs} --- массив правил типа \texttt{RdfRule}.
\end{itemize}

Предполагается, что при обработке исходных файлов используется некоторый инструмент десериализации CSV.

Структура \texttt{Dataset} содержит данные верхнего уровня конфигурационного файла --- единственный массив
\texttt{files} описаний \texttt{File} исходных файлов. При обработке \texttt{files} используется общая таблица фасетов
\texttt{entitiesFacets}, ассоциированных с соединительными сущностями. Результат преобразования всех файлов записывается
в единый файл \texttt{output.rdf}.

Модуль предоставляет функции \texttt{ProcessDataset} и \texttt{ProcessDatasets}, принимающие пути к одной корневой
директории или директории с несколькими корневыми директориями соответственно и выполняющие необходимые преобразования.

\subsection{Реализация преобразователя данных}

Для реализации преобразователя выбран язык программирования Go версии 1.22 по следующим причинам:
\begin{itemize}
  \item обладание всеми необходимыми механизмами абстракции и нативная поддержка многопоточности;
  \item обильная стандартная библиотека, предоставляющая, в частности, удобные инструменты работы с форматами YAML и
    CSV;
  \item компилируемость, обеспечивающая б\'{о}льшую скорость выполнения программ в сравнении с интерпретируемыми
    языками. Быстродействие преобразователя существенно, поскольку он рассчитан на работу с большими объёмами данных. 
\end{itemize}

\subsubsection{Модуль работы с RDF}

Модуль работы с RDF реализован в Go-пакете \texttt{rdf}. Пакет предоставляет тип \texttt{Decoration}, структуры
\texttt{Term}, \texttt{Facet}, \texttt{Rdf}, функции \texttt{NewTerm}, \texttt{NewFacet}, \texttt{NewRdf}
создания структур и методы \texttt{String} их сериализации (листинги \ref{lst:rdf:term}, \ref{lst:rdf:facet},
\ref{lst:rdf:rdf} приложения А соответственно).

\subsubsection{Модуль преобразования}

Модуль преобразования реализован в Go-пакете \texttt{converter}. Опишем основные особенности реализации модуля.

\paragraph{Обработка ошибок}

В реализации большое внимание уделяется валидации структур данных и обработке ошибок. При возникновении ошибки
соответствующий объект \texttt{error} передаётся среди возвращаемых значений задействованных функций, оборачивая
информацию об ошибке необходимым контекстом вплоть до вызова функций \texttt{ProcessDataset} и \texttt{ProcessDatasets}.

\paragraph{Публичные функции}

Реализация функции \texttt{ProcessDatasets} приводится в листинге \ref{lst:converter:processDatasets} приложения А.
Функция принимает путь к директории с корневыми директориями наборов данных, и для каждой директории вызывает метод
\texttt{ProcessDataset}. Вызовы происходят в отдельных горутинах с использованием механизма синхронизации
\texttt{errgroup} стандартного пакета \texttt{sync} языка Go. Если при обработке какого-либо набора возникает ошибка,
соответствующая горутина завершает свою работу, не влияя на работу остальных горутин, и функция \texttt{ProcessDatasets}
возвращает объект ошибки. В противном случае функция возвращает \texttt{nil}.

Реализация функции \texttt{ProcessDataset} приводится в листинге \ref{lst:converter:processDataset} приложения.
Функция принимает путь к корневой директории набора данных и средствами стандартного пакета \texttt{yaml.v3} языка Go
пробует десериализовать конфигурационный файл \texttt{convert.yml} во внутренние структуры модуля: \texttt{Dataset},
\texttt{File}, \texttt{Declaration} и пр. В случае успеха функция передаёт управление обработчику (методу обработки)
полученной структуры \texttt{Dataset}. При возникновении ошибки функция возвращает соответветствующий объект, а
иначе --- \texttt{nil}.

\paragraph{Внутренняя логика}

Обработчик структуры \texttt{Dataset} (листинг \ref{lst:converter:dataset.process} приложения А) создаёт файл
\texttt{output.rdf}, а также таблицу фасетов \texttt{entitiesFacets} на основе стандартной хеш-таблицы \texttt{map}
языка Go; \texttt{output.rdf} и \texttt{entitiesFacets} разделяются обработчиками всех объектов \texttt{files} набора
данных.

Обработчик структуры \texttt{File} (листинг \ref{lst:converter:file.process} приложения А) вначале валидирует
\texttt{delimiter}, \texttt{comment} и преобразует \texttt{declarations}, \texttt{artificial\_declaration} к удобному
для работы виду. Для десериализации исходного файла используется стандартный пакет \texttt{encoding/csv} языка Go. Для
каждой полученной записи вызываются функции применения правил сохранения фасетов (листинг \ref{lst:converter:saveFacets}
приложения А) и выписывания литералов RDF (листинг \ref{lst:converter:writeRdfs} приложения А). 

\subsubsection{Использование преобразователя}

Весь исходный код преобразователя находится в Git-репозитории~\cite{sources}. Для использования преобразователя на Linux
можно клонировать указанный репозиторий CLI-утилитой git и применить CLI-утилиту go, предназначенную для работы с
исходным кодом проектов на языке Go. Программа преобразования \texttt{convert.go} располагается в директории
\texttt{cmd/converter}.

Допустимые опции программы:
\begin{itemize}
  \item \texttt{dataset-path} --- путь к корневой директории набора данных;
  \item \texttt{datasets-path} --- путь к директории с корневыми директориями набора данных;
  \item \texttt{help} --- вывод допустимых опций программы.
\end{itemize}
Одновременно может быть установлена только одна из опций \texttt{dataset-path} и \texttt{datasets-path}.

\subsection{Выполнение запросов}

Для выполнения запросов Dgraph и оценки ресурсов, затраченных на их выполнение, написана вспомогательная программа.
Она значительно проще, чем программа преобразования, поэтому можно сразу перейти к её реализации.

\subsubsection{Реализация}

Языком реализации также является Go, поскольку Dgraph предоставляет официальный Go-клиент dgo~\cite{dgo}, который
взаимодействует с сервером Dgraph по протоколу gRPC. Этот пакет и будет использоваться при выполнении запросов,
поскольку предоставляет всю необходимую функциональность.

\paragraph{Установка соединения}

Программа устанавливает соединение с сервером Dgraph и возвращает клиент Dgraph; соответствующая функция приводится в
листинге \ref{lst:benchmark:dial} приложения А.

\paragraph{Выполнение транзакции}

В листинге \ref{lst:benchmark:perform} приложения А приводится функция выполнения запроса и оценки времени, оперативной
памяти, затраченных на его обработку. Поскольку запросы в рамках поставленной задачи только запрашивают данные и не
модифицируют их, для выполнения запросов клиентом Dgraph создаётся транзакция, предназначенная только для чтения
(read-only), которая может обрабатываться в обход общего протокола выполнения запроса и повысить скорость чтения.

\paragraph{Затраченное время}

Результат выполнения запроса содержит информацию о времени, затраченном на его обработку. А именно, это время (в
наносекундах)
\begin{itemize}
  \item синтаксического разбора текста запроса;
  \item непосредственно выполнения запроса;
  \item сериализации результата выполнения запроса;
\end{itemize}
Общее время выполнения запроса получается как сумма указанных значений.

\paragraph{Затраченная оперативная память}

Dgraph не предоставляет информации о потреблении оперативной памяти во время выполнения запроса. Чтобы получить эти
данные, в отдельном потоке при выполнении запроса с постоянным интервалом во времени отслеживается свободная оперативная
память и, в частности, её минимальное значение. Разница между свободной памятью до выполнения запроса и её минимальным
значением во время выполнения интерпретируется как потребление оперативной памяти. Разумеется, для получения корректных
результатов на основном устройстве не должны одновременно выполняться другие процессы, много и (или) непредсказуемо
потребляющие оперативную память.

Для получения информации о свободной оперативной памяти в программе используется внешний пакет
\texttt{pbnjay/memory}~\cite{pbnjayMemory}.

\subsubsection{Использование}

Исходный код программы \texttt{benchmark.go} также находится в git-репозитории~\cite{sources}, в каталоге
\texttt{cmd/benchmark}. Доступные опции программы:
\begin{itemize}
  \item \texttt{query-path} --- путь к файлу, содержащему единственный read-only запрос DQL;
  \item \texttt{host} --- хост сервера Dgraph (по умолчанию, \texttt{localhost});
  \item \texttt{port} --- gRPC-порт сервера Dgraph (по умолчнанию, \texttt{9080});
  \item \texttt{duration} --- временной интервал между замерами свободной оперативной памяти при выполнении запроса в
    формате аргумента функции \texttt{time.ParseDuration} стандартной библиотеки языка Go (по умолчанию,
    \texttt{100ms});
  \item \texttt{print-respond} --- требуется ли печатать результат выполнения запроса в формате JSON;
  \item \texttt{help} --- вывод доступных опций программы.
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
